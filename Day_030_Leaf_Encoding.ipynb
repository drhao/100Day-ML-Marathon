{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 作業 : (Kaggle)鐵達尼生存預測"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [教學目標]\n",
    "- 以下用鐵達尼預測資料, 展示如何使用葉編碼, 並觀察預測效果\n",
    "- 因為只有分類問題比較適合葉編碼, 因此範例與作業都使用鐵達尼的資料(二元分類問題)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [教學目標]\n",
    "- 了解葉編碼的寫作方式 : 使用梯度提升樹 (In[3]~In[5], Out[3]~Out[5])\n",
    "- 觀察葉編碼搭配邏輯斯迴歸後的效果 (In[6], Out[6], In[7], Out[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass                                               Name     Sex   Age  \\\n",
       "0       3                            Braund, Mr. Owen Harris    male  22.0   \n",
       "1       1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0   \n",
       "2       3                             Heikkinen, Miss. Laina  female  26.0   \n",
       "3       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0   \n",
       "4       3                           Allen, Mr. William Henry    male  35.0   \n",
       "\n",
       "   SibSp  Parch            Ticket     Fare Cabin Embarked  \n",
       "0      1      0         A/5 21171   7.2500   NaN        S  \n",
       "1      1      0          PC 17599  71.2833   C85        C  \n",
       "2      0      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      1      0            113803  53.1000  C123        S  \n",
       "4      0      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 做完特徵工程前的所有準備\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "# 因為擬合(fit)與編碼(transform)需要分開, 因此不使用.get_dummy, 而採用 sklearn 的 OneHotEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "data_path = 'data/'\n",
    "df = pd.read_csv(data_path + 'titanic_train.csv')\n",
    "\n",
    "train_Y = df['Survived']\n",
    "df = df.drop(['PassengerId', 'Survived'] , axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.121348</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.283951</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.769118</td>\n",
       "      <td>0.014151</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.213483</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.876471</td>\n",
       "      <td>0.139136</td>\n",
       "      <td>0.557823</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.396629</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.983824</td>\n",
       "      <td>0.015469</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.305618</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.072059</td>\n",
       "      <td>0.103644</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.016854</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.694118</td>\n",
       "      <td>0.015713</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass      Name  Sex       Age  SibSp  Parch    Ticket      Fare  \\\n",
       "0     1.0  0.121348  1.0  0.283951  0.125    0.0  0.769118  0.014151   \n",
       "1     0.0  0.213483  0.0  0.481481  0.125    0.0  0.876471  0.139136   \n",
       "2     1.0  0.396629  0.0  0.333333  0.000    0.0  0.983824  0.015469   \n",
       "3     0.0  0.305618  0.0  0.444444  0.125    0.0  0.072059  0.103644   \n",
       "4     1.0  0.016854  1.0  0.444444  0.000    0.0  0.694118  0.015713   \n",
       "\n",
       "      Cabin  Embarked  \n",
       "0  0.000000  1.000000  \n",
       "1  0.557823  0.333333  \n",
       "2  0.000000  1.000000  \n",
       "3  0.380952  1.000000  \n",
       "4  0.000000  1.000000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 因為需要把類別型與數值型特徵都加入, 故使用最簡版的特徵工程\n",
    "LEncoder = LabelEncoder()\n",
    "MMEncoder = MinMaxScaler()\n",
    "for c in df.columns:\n",
    "    df[c] = df[c].fillna(-1)\n",
    "    if df[c].dtype == 'object':\n",
    "        df[c] = LEncoder.fit_transform(list(df[c].values))\n",
    "    df[c] = MMEncoder.fit_transform(df[c].values.reshape(-1, 1))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = df.values\n",
    "# 因為訓練邏輯斯迴歸時也要資料, 因此將訓練及切成三部分 train / val / test, 採用 test 驗證而非 k-fold 交叉驗證\n",
    "# train 用來訓練梯度提升樹, val 用來訓練邏輯斯迴歸, test 驗證效果\n",
    "train_X, test_X, train_Y, test_Y = train_test_split(train_X, train_Y, test_size=0.5)\n",
    "train_X, val_X, train_Y, val_Y = train_test_split(train_X, train_Y, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=1000, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 梯度提升樹調整參數並擬合後, 再將葉編碼 (*.apply) 結果做獨熱 / 邏輯斯迴歸\n",
    "# 調整參數的方式採用 RandomSearchCV 或 GridSearchCV, 以後的進度會再教給大家, 本次先直接使用調參結果\n",
    "gdbt = GradientBoostingClassifier(subsample=0.93, n_estimators=320, min_samples_split=0.1, min_samples_leaf=0.3, \n",
    "                                  max_features=4, max_depth=4, learning_rate=0.16)\n",
    "onehot = OneHotEncoder()\n",
    "lr = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "\n",
    "gdbt.fit(train_X, train_Y)\n",
    "onehot.fit(gdbt.apply(train_X)[:, :, 0])\n",
    "lr.fit(onehot.transform(gdbt.apply(val_X)[:, :, 0]), val_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2., 2., 2., ..., 2., 1., 3.],\n",
       "       [1., 1., 1., ..., 2., 2., 3.],\n",
       "       [2., 2., 2., ..., 2., 2., 3.],\n",
       "       ...,\n",
       "       [1., 1., 1., ..., 1., 2., 2.],\n",
       "       [1., 1., 1., ..., 2., 1., 3.],\n",
       "       [1., 1., 1., ..., 2., 2., 3.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdbt.apply(train_X)[:, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將梯度提升樹+葉編碼+邏輯斯迴歸結果輸出\n",
    "pred_gdbt_lr = lr.predict_proba(onehot.transform(gdbt.apply(test_X)[:, :, 0]))[:, 1]\n",
    "fpr_gdbt_lr, tpr_gdbt_lr, _ = roc_curve(test_Y, pred_gdbt_lr)\n",
    "# 將梯度提升樹結果輸出\n",
    "pred_gdbt = gdbt.predict_proba(test_X)[:, 1]\n",
    "fpr_gdbt, tpr_gdbt, _ = roc_curve(test_Y, pred_gdbt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# 將結果繪圖\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_gdbt, tpr_gdbt, label='GDBT')\n",
    "plt.plot(fpr_gdbt_lr, tpr_gdbt_lr, label='GDBT + LR')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 作業1\n",
    "* 請對照範例，完成隨機森林的鐵達尼生存率預測，以及對應的葉編碼+邏輯斯迴歸\n",
    "\n",
    "# 作業2\n",
    "* 上述的結果，葉編碼是否有提高預測的正確性呢?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(222, 320, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdbt.apply(train_X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.887671  , 0.112329  ],\n",
       "       [0.96029139, 0.03970861],\n",
       "       [0.81592879, 0.18407121],\n",
       "       [0.54610985, 0.45389015],\n",
       "       [0.9812188 , 0.0187812 ],\n",
       "       [0.0813289 , 0.9186711 ],\n",
       "       [0.21570589, 0.78429411],\n",
       "       [0.97678475, 0.02321525],\n",
       "       [0.89511931, 0.10488069],\n",
       "       [0.69825145, 0.30174855],\n",
       "       [0.07965041, 0.92034959],\n",
       "       [0.90509942, 0.09490058],\n",
       "       [0.66280796, 0.33719204],\n",
       "       [0.05988224, 0.94011776],\n",
       "       [0.87692753, 0.12307247],\n",
       "       [0.93407036, 0.06592964],\n",
       "       [0.98130485, 0.01869515],\n",
       "       [0.21123798, 0.78876202],\n",
       "       [0.06813053, 0.93186947],\n",
       "       [0.14735188, 0.85264812],\n",
       "       [0.63710252, 0.36289748],\n",
       "       [0.9468443 , 0.0531557 ],\n",
       "       [0.60090321, 0.39909679],\n",
       "       [0.43450109, 0.56549891],\n",
       "       [0.9802109 , 0.0197891 ],\n",
       "       [0.34763396, 0.65236604],\n",
       "       [0.63450211, 0.36549789],\n",
       "       [0.08559339, 0.91440661],\n",
       "       [0.9096763 , 0.0903237 ],\n",
       "       [0.56324838, 0.43675162],\n",
       "       [0.88662373, 0.11337627],\n",
       "       [0.44387647, 0.55612353],\n",
       "       [0.10308096, 0.89691904],\n",
       "       [0.56266866, 0.43733134],\n",
       "       [0.94759181, 0.05240819],\n",
       "       [0.8892708 , 0.1107292 ],\n",
       "       [0.78324042, 0.21675958],\n",
       "       [0.14945713, 0.85054287],\n",
       "       [0.6360957 , 0.3639043 ],\n",
       "       [0.95783542, 0.04216458],\n",
       "       [0.91706548, 0.08293452],\n",
       "       [0.88662373, 0.11337627],\n",
       "       [0.9496999 , 0.0503001 ],\n",
       "       [0.56324838, 0.43675162],\n",
       "       [0.13101634, 0.86898366],\n",
       "       [0.84556068, 0.15443932],\n",
       "       [0.05988224, 0.94011776],\n",
       "       [0.09989944, 0.90010056],\n",
       "       [0.98621556, 0.01378444],\n",
       "       [0.95805017, 0.04194983],\n",
       "       [0.90087188, 0.09912812],\n",
       "       [0.94776472, 0.05223528],\n",
       "       [0.12158743, 0.87841257],\n",
       "       [0.84235235, 0.15764765],\n",
       "       [0.72803935, 0.27196065],\n",
       "       [0.15367882, 0.84632118],\n",
       "       [0.80043346, 0.19956654],\n",
       "       [0.42995519, 0.57004481],\n",
       "       [0.94718086, 0.05281914],\n",
       "       [0.43277551, 0.56722449],\n",
       "       [0.15108479, 0.84891521],\n",
       "       [0.6229748 , 0.3770252 ],\n",
       "       [0.95956618, 0.04043382],\n",
       "       [0.6255979 , 0.3744021 ],\n",
       "       [0.88991663, 0.11008337],\n",
       "       [0.94586791, 0.05413209],\n",
       "       [0.13101634, 0.86898366],\n",
       "       [0.91863068, 0.08136932],\n",
       "       [0.93360781, 0.06639219],\n",
       "       [0.35902265, 0.64097735],\n",
       "       [0.90803735, 0.09196265],\n",
       "       [0.55862772, 0.44137228],\n",
       "       [0.93086028, 0.06913972],\n",
       "       [0.0570552 , 0.9429448 ],\n",
       "       [0.09385228, 0.90614772],\n",
       "       [0.94575199, 0.05424801],\n",
       "       [0.2987131 , 0.7012869 ],\n",
       "       [0.54821007, 0.45178993],\n",
       "       [0.60090321, 0.39909679],\n",
       "       [0.84130974, 0.15869026],\n",
       "       [0.88690886, 0.11309114],\n",
       "       [0.38556419, 0.61443581],\n",
       "       [0.05988224, 0.94011776],\n",
       "       [0.97274122, 0.02725878],\n",
       "       [0.2881451 , 0.7118549 ],\n",
       "       [0.84423238, 0.15576762],\n",
       "       [0.84468969, 0.15531031],\n",
       "       [0.81812853, 0.18187147],\n",
       "       [0.86237226, 0.13762774],\n",
       "       [0.60697079, 0.39302921],\n",
       "       [0.30319438, 0.69680562],\n",
       "       [0.06761338, 0.93238662],\n",
       "       [0.87216894, 0.12783106],\n",
       "       [0.68782542, 0.31217458],\n",
       "       [0.13101634, 0.86898366],\n",
       "       [0.06761338, 0.93238662],\n",
       "       [0.72803935, 0.27196065],\n",
       "       [0.30929031, 0.69070969],\n",
       "       [0.68246133, 0.31753867],\n",
       "       [0.71054256, 0.28945744],\n",
       "       [0.98417098, 0.01582902],\n",
       "       [0.98171385, 0.01828615],\n",
       "       [0.90906664, 0.09093336],\n",
       "       [0.45237475, 0.54762525],\n",
       "       [0.40380421, 0.59619579],\n",
       "       [0.30275022, 0.69724978],\n",
       "       [0.10308096, 0.89691904],\n",
       "       [0.94718086, 0.05281914],\n",
       "       [0.57188718, 0.42811282],\n",
       "       [0.95197104, 0.04802896],\n",
       "       [0.94575786, 0.05424214],\n",
       "       [0.37118424, 0.62881576],\n",
       "       [0.55862772, 0.44137228],\n",
       "       [0.86102974, 0.13897026],\n",
       "       [0.23225986, 0.76774014],\n",
       "       [0.83444617, 0.16555383],\n",
       "       [0.64134864, 0.35865136],\n",
       "       [0.89572033, 0.10427967],\n",
       "       [0.57410821, 0.42589179],\n",
       "       [0.16057727, 0.83942273],\n",
       "       [0.79590761, 0.20409239],\n",
       "       [0.92147313, 0.07852687],\n",
       "       [0.55862772, 0.44137228],\n",
       "       [0.11174572, 0.88825428],\n",
       "       [0.89572033, 0.10427967],\n",
       "       [0.0813289 , 0.9186711 ],\n",
       "       [0.27740048, 0.72259952],\n",
       "       [0.15367882, 0.84632118],\n",
       "       [0.05570266, 0.94429734],\n",
       "       [0.98508548, 0.01491452],\n",
       "       [0.80968548, 0.19031452],\n",
       "       [0.78324042, 0.21675958],\n",
       "       [0.89219962, 0.10780038],\n",
       "       [0.83208734, 0.16791266],\n",
       "       [0.3877397 , 0.6122603 ],\n",
       "       [0.98630409, 0.01369591],\n",
       "       [0.61038609, 0.38961391],\n",
       "       [0.0813289 , 0.9186711 ],\n",
       "       [0.90667474, 0.09332526],\n",
       "       [0.3194909 , 0.6805091 ],\n",
       "       [0.9680701 , 0.0319299 ],\n",
       "       [0.35425599, 0.64574401],\n",
       "       [0.54610985, 0.45389015],\n",
       "       [0.8812768 , 0.1187232 ],\n",
       "       [0.90466433, 0.09533567],\n",
       "       [0.91518902, 0.08481098],\n",
       "       [0.89056522, 0.10943478],\n",
       "       [0.06761338, 0.93238662],\n",
       "       [0.89879702, 0.10120298],\n",
       "       [0.78525173, 0.21474827],\n",
       "       [0.60090321, 0.39909679],\n",
       "       [0.96488045, 0.03511955],\n",
       "       [0.91435797, 0.08564203],\n",
       "       [0.0570552 , 0.9429448 ],\n",
       "       [0.93201324, 0.06798676],\n",
       "       [0.43450109, 0.56549891],\n",
       "       [0.887671  , 0.112329  ],\n",
       "       [0.8812768 , 0.1187232 ],\n",
       "       [0.93369443, 0.06630557],\n",
       "       [0.68978291, 0.31021709],\n",
       "       [0.63450211, 0.36549789],\n",
       "       [0.0570552 , 0.9429448 ],\n",
       "       [0.08101807, 0.91898193],\n",
       "       [0.47521447, 0.52478553],\n",
       "       [0.276005  , 0.723995  ],\n",
       "       [0.84985446, 0.15014554],\n",
       "       [0.84556068, 0.15443932],\n",
       "       [0.93419456, 0.06580544],\n",
       "       [0.6930716 , 0.3069284 ],\n",
       "       [0.83444617, 0.16555383],\n",
       "       [0.84316572, 0.15683428],\n",
       "       [0.887671  , 0.112329  ],\n",
       "       [0.3216509 , 0.6783491 ],\n",
       "       [0.92880922, 0.07119078],\n",
       "       [0.6696429 , 0.3303571 ],\n",
       "       [0.40641418, 0.59358582],\n",
       "       [0.92462577, 0.07537423],\n",
       "       [0.29967626, 0.70032374],\n",
       "       [0.06299459, 0.93700541],\n",
       "       [0.9182525 , 0.0817475 ],\n",
       "       [0.94302223, 0.05697777],\n",
       "       [0.54610985, 0.45389015],\n",
       "       [0.90914284, 0.09085716],\n",
       "       [0.08698517, 0.91301483],\n",
       "       [0.46742211, 0.53257789],\n",
       "       [0.80660689, 0.19339311],\n",
       "       [0.16015284, 0.83984716],\n",
       "       [0.89572033, 0.10427967],\n",
       "       [0.94955234, 0.05044766],\n",
       "       [0.05988224, 0.94011776],\n",
       "       [0.91086411, 0.08913589],\n",
       "       [0.92006748, 0.07993252],\n",
       "       [0.55862772, 0.44137228],\n",
       "       [0.97962133, 0.02037867],\n",
       "       [0.1037613 , 0.8962387 ],\n",
       "       [0.13623239, 0.86376761],\n",
       "       [0.94979847, 0.05020153],\n",
       "       [0.93407036, 0.06592964],\n",
       "       [0.05988224, 0.94011776],\n",
       "       [0.08101807, 0.91898193],\n",
       "       [0.57221138, 0.42778862],\n",
       "       [0.54610985, 0.45389015],\n",
       "       [0.55862772, 0.44137228],\n",
       "       [0.69629203, 0.30370797],\n",
       "       [0.88150328, 0.11849672],\n",
       "       [0.58250459, 0.41749541],\n",
       "       [0.38605996, 0.61394004],\n",
       "       [0.91764558, 0.08235442],\n",
       "       [0.44453741, 0.55546259],\n",
       "       [0.96105965, 0.03894035],\n",
       "       [0.11423215, 0.88576785],\n",
       "       [0.55862772, 0.44137228],\n",
       "       [0.1139335 , 0.8860665 ],\n",
       "       [0.91873067, 0.08126933],\n",
       "       [0.89572033, 0.10427967],\n",
       "       [0.94979847, 0.05020153],\n",
       "       [0.94391833, 0.05608167],\n",
       "       [0.96891677, 0.03108323],\n",
       "       [0.28654426, 0.71345574],\n",
       "       [0.65956422, 0.34043578],\n",
       "       [0.93903184, 0.06096816],\n",
       "       [0.88719939, 0.11280061],\n",
       "       [0.21883669, 0.78116331],\n",
       "       [0.95711452, 0.04288548],\n",
       "       [0.92019582, 0.07980418],\n",
       "       [0.67166387, 0.32833613],\n",
       "       [0.81233468, 0.18766532],\n",
       "       [0.55862772, 0.44137228],\n",
       "       [0.88105657, 0.11894343],\n",
       "       [0.87348424, 0.12651576],\n",
       "       [0.28654426, 0.71345574],\n",
       "       [0.54324035, 0.45675965],\n",
       "       [0.78212483, 0.21787517],\n",
       "       [0.41779406, 0.58220594],\n",
       "       [0.78603805, 0.21396195],\n",
       "       [0.10314781, 0.89685219],\n",
       "       [0.43368158, 0.56631842],\n",
       "       [0.94383326, 0.05616674],\n",
       "       [0.65504326, 0.34495674],\n",
       "       [0.52701786, 0.47298214],\n",
       "       [0.58119245, 0.41880755],\n",
       "       [0.90898878, 0.09101122],\n",
       "       [0.40901987, 0.59098013],\n",
       "       [0.90876991, 0.09123009],\n",
       "       [0.88662373, 0.11337627],\n",
       "       [0.13101634, 0.86898366],\n",
       "       [0.73167209, 0.26832791],\n",
       "       [0.84747934, 0.15252066],\n",
       "       [0.70025942, 0.29974058],\n",
       "       [0.0411495 , 0.9588505 ],\n",
       "       [0.9038678 , 0.0961322 ],\n",
       "       [0.88662373, 0.11337627],\n",
       "       [0.66034257, 0.33965743],\n",
       "       [0.94302223, 0.05697777],\n",
       "       [0.43368158, 0.56631842],\n",
       "       [0.85037482, 0.14962518],\n",
       "       [0.06090386, 0.93909614],\n",
       "       [0.91008631, 0.08991369],\n",
       "       [0.83931359, 0.16068641],\n",
       "       [0.58123176, 0.41876824],\n",
       "       [0.68261972, 0.31738028],\n",
       "       [0.5513232 , 0.4486768 ],\n",
       "       [0.89558135, 0.10441865],\n",
       "       [0.81357148, 0.18642852],\n",
       "       [0.27724667, 0.72275333],\n",
       "       [0.93913986, 0.06086014],\n",
       "       [0.87467636, 0.12532364],\n",
       "       [0.95158725, 0.04841275],\n",
       "       [0.88719939, 0.11280061],\n",
       "       [0.62927608, 0.37072392],\n",
       "       [0.14263557, 0.85736443],\n",
       "       [0.08245283, 0.91754717],\n",
       "       [0.98454564, 0.01545436],\n",
       "       [0.342488  , 0.657512  ],\n",
       "       [0.81235213, 0.18764787],\n",
       "       [0.75047574, 0.24952426],\n",
       "       [0.17804148, 0.82195852],\n",
       "       [0.72803935, 0.27196065],\n",
       "       [0.27740048, 0.72259952],\n",
       "       [0.36494592, 0.63505408],\n",
       "       [0.75659843, 0.24340157],\n",
       "       [0.90480807, 0.09519193],\n",
       "       [0.243583  , 0.756417  ],\n",
       "       [0.84719273, 0.15280727],\n",
       "       [0.5331341 , 0.4668659 ],\n",
       "       [0.42378412, 0.57621588],\n",
       "       [0.63492993, 0.36507007],\n",
       "       [0.77528287, 0.22471713],\n",
       "       [0.16864906, 0.83135094],\n",
       "       [0.40144099, 0.59855901],\n",
       "       [0.06761338, 0.93238662],\n",
       "       [0.86288789, 0.13711211],\n",
       "       [0.44432397, 0.55567603],\n",
       "       [0.28448416, 0.71551584],\n",
       "       [0.0570552 , 0.9429448 ],\n",
       "       [0.05988224, 0.94011776],\n",
       "       [0.94718086, 0.05281914],\n",
       "       [0.96815466, 0.03184534],\n",
       "       [0.89511931, 0.10488069],\n",
       "       [0.89286635, 0.10713365],\n",
       "       [0.59993964, 0.40006036],\n",
       "       [0.93597629, 0.06402371],\n",
       "       [0.05981457, 0.94018543],\n",
       "       [0.06844925, 0.93155075],\n",
       "       [0.13623239, 0.86376761],\n",
       "       [0.86871658, 0.13128342],\n",
       "       [0.85831497, 0.14168503],\n",
       "       [0.52104756, 0.47895244],\n",
       "       [0.97421233, 0.02578767],\n",
       "       [0.73398324, 0.26601676],\n",
       "       [0.15367882, 0.84632118],\n",
       "       [0.85377325, 0.14622675],\n",
       "       [0.85999083, 0.14000917],\n",
       "       [0.72803935, 0.27196065],\n",
       "       [0.88320927, 0.11679073],\n",
       "       [0.96703756, 0.03296244],\n",
       "       [0.81830409, 0.18169591],\n",
       "       [0.94386166, 0.05613834],\n",
       "       [0.05988224, 0.94011776],\n",
       "       [0.94052835, 0.05947165],\n",
       "       [0.28750622, 0.71249378],\n",
       "       [0.81854496, 0.18145504],\n",
       "       [0.14755815, 0.85244185],\n",
       "       [0.16057727, 0.83942273],\n",
       "       [0.98630409, 0.01369591],\n",
       "       [0.88662373, 0.11337627],\n",
       "       [0.54610985, 0.45389015],\n",
       "       [0.25807058, 0.74192942],\n",
       "       [0.79126695, 0.20873305],\n",
       "       [0.61456503, 0.38543497],\n",
       "       [0.95197104, 0.04802896],\n",
       "       [0.39085088, 0.60914912],\n",
       "       [0.92147313, 0.07852687],\n",
       "       [0.77976617, 0.22023383],\n",
       "       [0.91921241, 0.08078759],\n",
       "       [0.94990548, 0.05009452],\n",
       "       [0.96943084, 0.03056916],\n",
       "       [0.36668602, 0.63331398],\n",
       "       [0.93597629, 0.06402371],\n",
       "       [0.84468969, 0.15531031],\n",
       "       [0.37714068, 0.62285932],\n",
       "       [0.92147313, 0.07852687],\n",
       "       [0.84758017, 0.15241983],\n",
       "       [0.91086411, 0.08913589],\n",
       "       [0.08245283, 0.91754717],\n",
       "       [0.80895101, 0.19104899],\n",
       "       [0.43368158, 0.56631842],\n",
       "       [0.89399055, 0.10600945],\n",
       "       [0.89289337, 0.10710663],\n",
       "       [0.55862772, 0.44137228],\n",
       "       [0.59993964, 0.40006036],\n",
       "       [0.73185924, 0.26814076],\n",
       "       [0.3877397 , 0.6122603 ],\n",
       "       [0.23695012, 0.76304988],\n",
       "       [0.67056417, 0.32943583],\n",
       "       [0.34460034, 0.65539966],\n",
       "       [0.63710252, 0.36289748],\n",
       "       [0.90150233, 0.09849767],\n",
       "       [0.72803935, 0.27196065],\n",
       "       [0.86854143, 0.13145857],\n",
       "       [0.64676154, 0.35323846],\n",
       "       [0.94635829, 0.05364171],\n",
       "       [0.9096763 , 0.0903237 ],\n",
       "       [0.86854143, 0.13145857],\n",
       "       [0.56470559, 0.43529441],\n",
       "       [0.91761703, 0.08238297],\n",
       "       [0.69963306, 0.30036694],\n",
       "       [0.04955079, 0.95044921],\n",
       "       [0.60090321, 0.39909679],\n",
       "       [0.06844925, 0.93155075],\n",
       "       [0.17143474, 0.82856526],\n",
       "       [0.67056417, 0.32943583],\n",
       "       [0.26503997, 0.73496003],\n",
       "       [0.91921241, 0.08078759],\n",
       "       [0.55862772, 0.44137228],\n",
       "       [0.14755815, 0.85244185],\n",
       "       [0.81335204, 0.18664796],\n",
       "       [0.37145439, 0.62854561],\n",
       "       [0.94306553, 0.05693447],\n",
       "       [0.94579412, 0.05420588],\n",
       "       [0.85337705, 0.14662295],\n",
       "       [0.06761338, 0.93238662],\n",
       "       [0.15599774, 0.84400226],\n",
       "       [0.94586791, 0.05413209],\n",
       "       [0.6930716 , 0.3069284 ],\n",
       "       [0.94979847, 0.05020153],\n",
       "       [0.95566999, 0.04433001],\n",
       "       [0.0570552 , 0.9429448 ],\n",
       "       [0.86329181, 0.13670819],\n",
       "       [0.90087188, 0.09912812],\n",
       "       [0.94191762, 0.05808238],\n",
       "       [0.78603805, 0.21396195],\n",
       "       [0.54610985, 0.45389015],\n",
       "       [0.96891677, 0.03108323],\n",
       "       [0.87319654, 0.12680346],\n",
       "       [0.14735188, 0.85264812],\n",
       "       [0.95197104, 0.04802896],\n",
       "       [0.10144896, 0.89855104],\n",
       "       [0.15367882, 0.84632118],\n",
       "       [0.72803935, 0.27196065],\n",
       "       [0.93117051, 0.06882949],\n",
       "       [0.99002468, 0.00997532],\n",
       "       [0.96846821, 0.03153179],\n",
       "       [0.61481097, 0.38518903],\n",
       "       [0.91921241, 0.08078759],\n",
       "       [0.96592327, 0.03407673],\n",
       "       [0.06761338, 0.93238662],\n",
       "       [0.74402762, 0.25597238],\n",
       "       [0.57685985, 0.42314015],\n",
       "       [0.59993964, 0.40006036],\n",
       "       [0.94342856, 0.05657144],\n",
       "       [0.59131713, 0.40868287],\n",
       "       [0.95964771, 0.04035229],\n",
       "       [0.73185924, 0.26814076],\n",
       "       [0.8384522 , 0.1615478 ],\n",
       "       [0.91921241, 0.08078759],\n",
       "       [0.96700794, 0.03299206],\n",
       "       [0.06761338, 0.93238662],\n",
       "       [0.54099335, 0.45900665],\n",
       "       [0.1713591 , 0.8286409 ],\n",
       "       [0.98130346, 0.01869654],\n",
       "       [0.86854143, 0.13145857],\n",
       "       [0.73185924, 0.26814076],\n",
       "       [0.68782542, 0.31217458],\n",
       "       [0.06577252, 0.93422748],\n",
       "       [0.41232022, 0.58767978],\n",
       "       [0.72803935, 0.27196065],\n",
       "       [0.06761338, 0.93238662],\n",
       "       [0.94635829, 0.05364171],\n",
       "       [0.1722798 , 0.8277202 ],\n",
       "       [0.87432198, 0.12567802],\n",
       "       [0.35160563, 0.64839437],\n",
       "       [0.94302223, 0.05697777],\n",
       "       [0.76446346, 0.23553654],\n",
       "       [0.6345845 , 0.3654155 ],\n",
       "       [0.73185924, 0.26814076],\n",
       "       [0.71054256, 0.28945744],\n",
       "       [0.96959442, 0.03040558],\n",
       "       [0.90897613, 0.09102387],\n",
       "       [0.89220374, 0.10779626],\n",
       "       [0.06761338, 0.93238662],\n",
       "       [0.86561205, 0.13438795],\n",
       "       [0.89558135, 0.10441865],\n",
       "       [0.08101807, 0.91898193],\n",
       "       [0.86167907, 0.13832093],\n",
       "       [0.91171816, 0.08828184]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdbt.predict_proba(test_X)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
